{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "## a)\n",
    "\n",
    "The insurance company has the major advantage that it already has what is potentially the largest cost factor in text analysis projects, the data. The problem, however, is that this data is only available in the form of scans and must first be converted into semi-structured document data. This is something that needs to be taken into special consideration in a project of this kind.\n",
    "\n",
    "One of the main challenges of a text analysis project in this context is that the objectives of this project are very vaguely formulated. Concrete objectives that can be tested against KPIs are not present as described in the exercise explanation. Only the objective \"extract datailed insights into customer needs\" is given as a specification. A possible example for a concretization is listed below. Accordingly, the objective is derived from the driver, which in this case is derived from the existing data. In the following, the four essential factors are taken up again in detail:\n",
    "\n",
    "- Driver: Main driver is the accessibility to new text data, which is given by the digitized customer related forms.\n",
    "- Objective: There is only the abstract goal to extract detailed insights in customer needs. This is an more or less abstract goal which must be concretized and might be measurable by KPIs. An example approach would be to analyze the descriptions of traffic accidents in terms of where damage was done at cars and create new insurance products based on different parts of cars. \n",
    "- Data: The goal of the project is to analyze the newly digitized data, so the data is given. Probably there is a lot of work to do to transform the scans to semi-structured data, since scans are mostly hard to interpret.\n",
    "- Costs: Due to the existence of data, costs are more or less given by developing strategies and implementing the aimed approaches. Since usual insurance workers mostly aren't used to work with text analytics approach the insurance company must invest in new stuff members, which are educated in this area. This comes whith quite huge costs, since data scientists are quite popular at the job market. Furthermore, the insurance company might invest in software licenses. This depends on the usage of different models / software, etc. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)\n",
    "\n",
    "**Cons Elasticsearch over RDBMS:**\n",
    "\n",
    "- Data Integrity: Relational databases ensure the correctness, completeness and consistency of the data as well as the ACID paradigm. Among other things, this is made possible by complete transactions including rollbacks, by using unique primary and foreign keys between the relations / tables, referenced updates, inserts and deletes (keyword: cascading). Elasticsearch does not have a mechanism that fully guarantees any of these things. The use of schemas within Elasticsearch at least ensures consistency within a document, but relational integrity is very complex to map. In particular, Elasticsearch has problems mapping changing dependencies such as those that occur with frequent updates, deletes, and inserts of relational links. Examples of a particularly relevant aspect concerning this issue are enterprise resource planning systems, which on the one hand require fixed transactions and on the other hand have many dependencies between customers, products, etc. In this case, a relational database is much more suitable.\n",
    "- Data Queries: Complicated data queries with groupings, joins of different relations, mathematical calculations, etc. are very easy to perform with relational databases using SQL. Elasticsearch, on the other hand, as a text-oriented document store, is only partially prepared for these types of queries and requires a significant amount of extra work.\n",
    "\n",
    "**Pros Elasticsearch over RDMS:**\n",
    "\n",
    "- Speed: Elasticsearch was designed to store textual data in a quickly accessible manner. Especially in the context of information retrieval, how long a query to the database takes plays a significant role. Just imagine if the auto-completion of a search query took several seconds - the functionality would be useless. Relational databases, especially for large, distributed systems, on the other hand, take much longer to process data - even in the context of performing full transactions, which requires significant extra effort to synchronize.\n",
    "- Flexibility: Elasticsearch does not impose any constraints on the schema of the data to be inserted. This increases flexibility in the use of Elasticsearch. In particular, data types, nesting, etc. can be freely chosen or alternatively determined by Elasticsearch's independent discovery. Relational databases require a fixed specification of data types, relations, etc. before data can be inserted. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c)\n",
    "\n",
    "### i) Stop word removal\n",
    "\n",
    "| Pros | Cons |\n",
    "|--|--|\n",
    "| - Test | - Test2 |\n",
    "\n",
    "### ii) Stemming\n",
    "\n",
    "| Pros | Cons |\n",
    "|--|--|\n",
    "| - Test | - Test2 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
