{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "## a)\n",
    "\n",
    "The insurance company has the major advantage that it already has what is potentially the largest cost factor in text analysis projects, the data. The problem, however, is that this data is only available in the form of scans and must first be converted into semi-structured document data. This is something that needs to be taken into special consideration in a project of this kind.\n",
    "\n",
    "One of the main challenges of a text analysis project in this context is that the objectives of this project are very vaguely formulated. Concrete objectives that can be tested against KPIs are not present as described in the exercise explanation. Only the objective \"extract datailed insights into customer needs\" is given as a specification. A possible example for a concretization is listed below. Accordingly, the objective is derived from the driver, which in this case is derived from the existing data. In the following, the four essential factors are taken up again in detail:\n",
    "\n",
    "- Driver: Main driver is the accessibility to new text data, which is given by the digitized customer related forms.\n",
    "- Objective: There is only the abstract goal to extract detailed insights in customer needs. This is an more or less abstract goal which must be concretized and might be measurable by KPIs. An example approach would be to analyze the descriptions of traffic accidents in terms of where damage was done at cars and create new insurance products based on different parts of cars. \n",
    "- Data: The goal of the project is to analyze the newly digitized data, so the data is given. Probably there is a lot of work to do to transform the scans to semi-structured data, since scans are mostly hard to interpret.\n",
    "- Costs: Due to the existence of data, costs are more or less given by developing strategies and implementing the aimed approaches. Since usual insurance workers mostly aren't used to work with text analytics approach the insurance company must invest in new stuff members, which are educated in this area. This comes whith quite huge costs, since data scientists are quite popular at the job market. Furthermore, the insurance company might invest in software licenses. This depends on the usage of different models / software, etc. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)\n",
    "\n",
    "**Cons Elasticsearch over RDBMS:**\n",
    "\n",
    "- Data Integrity: Relational databases ensure the correctness, completeness and consistency of the data as well as the ACID paradigm. Among other things, this is made possible by complete transactions including rollbacks, by using unique primary and foreign keys between the relations / tables, referenced updates, inserts and deletes (keyword: cascading). Elasticsearch does not have a mechanism that fully guarantees any of these things. The use of schemas within Elasticsearch at least ensures consistency within a document, but relational integrity is very complex to map. In particular, Elasticsearch has problems mapping changing dependencies such as those that occur with frequent updates, deletes, and inserts of relational links. Examples of a particularly relevant aspect concerning this issue are enterprise resource planning systems, which on the one hand require fixed transactions and on the other hand have many dependencies between customers, products, etc. In this case, a relational database is much more suitable.\n",
    "- Data Queries: Complicated data queries with groupings, joins of different relations, mathematical calculations, etc. are very easy to perform with relational databases using SQL. Elasticsearch, on the other hand, as a text-oriented document store, is only partially prepared for these types of queries and requires a significant amount of extra work.\n",
    "\n",
    "**Pros Elasticsearch over RDMS:**\n",
    "\n",
    "- Speed: Elasticsearch was designed to store textual data in a quickly accessible manner. Especially in the context of information retrieval, how long a query to the database takes plays a significant role. Just imagine if the auto-completion of a search query took several seconds - the functionality would be useless. Relational databases, especially for large, distributed systems, on the other hand, take much longer to process data - even in the context of performing full transactions, which requires significant extra effort to synchronize.\n",
    "- Flexibility: Elasticsearch does not impose any constraints on the schema of the data to be inserted. This increases flexibility in the use of Elasticsearch. In particular, data types, nesting, etc. can be freely chosen or alternatively determined by Elasticsearch's independent discovery. Relational databases require a fixed specification of data types, relations, etc. before data can be inserted. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c)\n",
    "\n",
    "### i) Stop word removal\n",
    "\n",
    "**Pros:**\n",
    "- Stop word removal helps to extract the main aspects of a document and filter out low-level information of the document. Words like \"the\", \"a\", \"an\", \"so\", \"what\" don't keep important information to most documents, so it might be unnecessary to consider them, when focusing on the most important aspects of a document.\n",
    "- Stop word removal reduces the size of data to process and to store. Especially when building machine learning models, a reduced size of datasets improves computation time. Consider sentences containing words like described above, those words shouldn't have any impact on any NLP task.\n",
    "\n",
    "\n",
    "**Cons:**\n",
    "- Stop word removal might delete the main aspects of given sentences. Consider the Shakespeare quote \"To be or not to be.\", which might be cut off completely by some stop word removal algorithms (source: https://www.elastic.co/de/blog/stop-stopping-stop-words-a-look-at-common-terms-query).\n",
    "- Stop word removal also can lead to possible misinterpretation of text, especially in context of sentiment analysis. The sentence \"I told you that she was not happy\" might be cut to the set of words {told, happy} which yields to a positive sentiment of the sentences - but that's not the case (source: https://medium.com/@limavallantin/why-is-removing-stop-words-not-always-a-good-idea-c8d35bd77214).\n",
    "\n",
    "### ii) Stemming\n",
    "\n",
    "**Pros:**\n",
    "- Stemming reduces the size of the search index and thus computation time when searching for data. For words with the same \"kernel\", like \"argue, argued, argues, arguing, argus\" will be mapped to \"argu\". When retrieving data by doing a search query, all possible expressions of \"argu\" will be considered and not only the exact one. (source: https://en.wikipedia.org/wiki/Stemming)\n",
    "- Stemming helps to build more meaningful NLP models, since the text data is more compressed. If one would keep all the expressions mentioned above when building a pipeline, each expression will be considered as a single item. Contrary, if one uses stemming to compress the data, the expression \"argu\" gets a higher score for each occurrence of its non-stemmed origin. This might be useful for classification tasks, as well as sentiment analysis. For sentiment analysis, stemming makes it easier to pre-classify, since only the stemmed words have to be classified manually before any computation and not every single expression.\n",
    "\n",
    "**Cons:**\n",
    "- Stemming algorithms aren't perfect in terms of finding the right root word for every word. Especially for words which change many times in different grammar settings, stemming won't map the right words together. For example, the word \"better\" ideally should be mapped to \"good\", but stemming without any additional algorithm might not be able to detect this connection.\n",
    "- Stemming might affect in under stemming or over stemming. Over stemming means that words are mapped to the same source, which have different meanings. For example, consider \"universal\", \"university\", \"universe\", which will be mapped to \"univers\". Contrary, under stemming is about not finding common words by a stemming algorithm. One famous stemming algorithm, Porters algorithm, maps \"alumnus\" to \"alumnu\", \"alumni\" to \"alumni\" and \"alumna\"/\"alumnae\" to \"alumna\". These words should be considered as synonyms. (source: https://en.wikipedia.org/wiki/Stemming)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
