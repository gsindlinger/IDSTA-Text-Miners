{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6091b229-84bc-4b6a-9b2f-ef8682e36741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import matplotlib\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "421dfdb4-c47d-44c5-ac16-a8955f98fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load dataset\n",
    "with open('only_german_lyrics.json', 'r') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154c39f-bfba-492c-abf4-6d530706dd13",
   "metadata": {
    "tags": []
   },
   "source": [
    "## preprocessing the lyrics\n",
    "1) removing stopwords\n",
    "2) removing punctuation\n",
    "3) saving the processed lyrics inside the dictionary under ['processed_lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c459c1c-a57c-4759-b14f-be5bd82431cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0471182538b44a49675e5ca3fd0fe3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=5992)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\", exclude=\"ner\")\n",
    "stopwords_de = spacy.lang.de.stop_words.STOP_WORDS\n",
    "f = IntProgress(min=0, max=5992) # instantiate the bar\n",
    "display(f) # display the bar\n",
    "word_list = []\n",
    "i = 0\n",
    "for key in dataset.keys():\n",
    "    for idx in dataset[key]:\n",
    "        song_filtered = []\n",
    "        for line in dataset[key][idx]['lyrics'].split(\"\\n\"):\n",
    "            line_list = \"\"\n",
    "            for word in nlp(str(line)):\n",
    "                if not word.lemma_ in stopwords_de and word.has_vector:\n",
    "                    if not word.is_punct:\n",
    "                    # if word.text != '\\n' and word.text != '\\n\\n' and word.text != '\\n\\n\\n' and word.text != ',' and word.text !=:\n",
    "                        line_list += word.text + \" \"\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            song_filtered.append(line_list)\n",
    "        dataset[key][idx].update({'processed_lyrics' : song_filtered})\n",
    "    f.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "447bbd8f-7834-4736-8b51-c2a36c0e5106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new dictionary as .json\n",
    "with open('preprocessed_only_german_lyrics' + '.json', 'w', encoding='utf8') as f:\n",
    "    json.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ef8aa7-ca2c-4127-a457-d37017c94764",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training Word2Vec\n",
    "### 2 approaches:\n",
    "- analyse only nouns\n",
    "- analyse whatever the previous step gave us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa80e48f-f8b6-480e-b98b-512fbc921673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "  ## preprocessing ##\n",
    "## Each sentence be placed in its own index and inside we will have the words of the sentence in a list \n",
    "processed_lyrics_lowcase = []\n",
    "sentences_list_lowcase = []\n",
    "for key in dataset.keys():\n",
    "    for idx in dataset[key]:\n",
    "        for sentence in dataset[key][idx]['processed_lyrics']:\n",
    "            words_list = []\n",
    "            words_string = \"\"\n",
    "            for word in sentence.split(\" \"):\n",
    "                if word == '':\n",
    "                    continue\n",
    "                words_list.append(word.lower())\n",
    "                words_string += word + \" \"\n",
    "            sentences_list_lowcase.append(words_list)\n",
    "            processed_lyrics_lowcase.append(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29dec2d3-6d9b-4af9-bf57-78a6820e1282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the new dictionary as .json\n",
    "with open('preprocessed_only_german_lyrics.json', 'r', encoding='utf8') as f:\n",
    "    new_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6681daea-972a-4a11-ba96-1e10d1dfa74f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Füchse',\n",
       " 'album': 'Bambule',\n",
       " 'album_cover': 'https://images.genius.com/402fea79dcbeed4370b8e9e67362752d.800x793x1.jpg',\n",
       " 'genius_album_id': 11330,\n",
       " 'release_date': '1998-11-10',\n",
       " 'featured_artists': ['Samy Deluxe'],\n",
       " 'featured_artists_pics': ['https://s3.amazonaws.com/rapgenius/Samy-Deluxe.jpg'],\n",
       " 'producer_artists': ['Eizi Eiz', 'Platin Martin'],\n",
       " 'writer_artists': ['Denyo', 'Samy Deluxe', 'Eizi Eiz'],\n",
       " 'primary_artist_picture': 'https://s3.amazonaws.com/rapgenius/1355220276_photo.jpg',\n",
       " 'lyrics_path': '/Beginner-fuchse-lyrics',\n",
       " 'genius_track_id': 52626,\n",
       " 'lyrics': '\\n\\nWickeda-MC., mit Flows pur Natur wie Sensi.\\nUnd Freestyles näher am Geschehen als jedes Hip-Hop-Fanzine.\\nFuchs\\' mich in die Materie.,  da es Möglichkeiten unbegrenzt gibt.\\nLeider folgen viele falschen Vorbildern und lernen\\'s nie.\\nDas Publikum zu rocken, da es auf \\'ner anderen Frequenz liegt.\\nWas uns nicht betrifft, weil man unsere Bühnenpräsenz liebt.\\nUnd Rap-Exzellenz sieht, die sich der Vorstellungskraft Vieler entzieht.\\nSam Semilia.\\nund die Beginner, ihr kennt sie! - Woh!\\n\\nAu, der Magen knurrt wie Sau.\\nIch hau\\' ab aus meinem Bau.\\nVerschließ\\' die Tür, ziehe durch\\'s Revier.\\nMarkier\\' hier und da mal, dass ich da war.\\nHöre Gelaber,.\\nschleiche.\\ngerade über die Promenade.\\nZeuge einer großen Maskerade.\\nGroße Buchstaben, grelle Farben.\\nDie mir sagen, dass sie Kabelfernsehen haben.\\nGestiken von Gerngesehenen, aber jeder Fuchs weiß.\\nDass ähnliche Garderobe heute leider nicht mehr Schutz heißt.\\nDeshalb schnupper\\' ich, was befindet sich darunter?.\\nImmer auf der Hut - wie Udo darunter!\\n\\nJede Nacht, jeden Tag auf der Jagd.\\nDenn das Rudel tollt, wenn der Rubel rollt.\\nJede Nacht, jeden Tag auf der Jagd.\\nDenn das Rudel tollt, wenn der Rubel rollt.\\nJede Nacht, jeden Tag auf der Jagd.\\nDenn das Rudel tollt, wenn der Rubel rollt.\\nJede Nacht, jeden Tag auf der Jagd.\\nDenn das Rudel tollt, wenn der Rubel rollt\\n\\nWir haben Pfoten wie Gabi,.\\nMikros als Boten für Rap Schoten.\\nVerboten Quoten-MCs auf unserem Boden zu toben.\\nDurchkreuzen Wälder, wir werden älter,.\\nAlter wird\\'s kälter.\\nEgal, nicht für\\'n warmen Platz bin ich beim Major.\\nPress\\' Vitamine aus Rap wie aus Orangen Granini.\\nVerteil\\' Beginner-Sticker wie Panini, ernten Platini.\\nOhne I und ohne Style-tauschen.\\nWenn ich Mega-Byte gestalt\\' ich Hits zum \\'reinlauschen.\\nWenn Beats im Reim rauschen: Macht nix.\\nWas dreckig ist, kehr\\'n wir nicht unter\\'n Teppich.\\nDer Grund warum ich ständig Loops aufgepeppt krieg\\'.\\nViele vergeigen bloß.\\nMir egal, wenn bei mir alle Stricke reißen, bin ich den Galgen los.\\nWir stylen groß!.\\nDu siehst mit List gefuchste Clips, guckst\\'e Gigs.\\nVon den Beginnern im TV, geklaut ist bei uns nix.\\nUnd kriegt wer Futterneid, tut uns leid, kommt vor, bei soviel Geilheit.\\nZahme.\\nVögel.\\nsingen wie Münchener von Freiheit.\\nKein Sinneswandel, keine Floskel, ungeschminkt, ich bleib\\' da.\\nUnd werd\\' bestimmt nicht Amsel, Drossel oder Fink – ich bleib\\' Star!\\n\\nJede Nacht, jeden Tag auf der Jagd.\\nDenn das Rudel tollt, wenn der Rubel rollt.\\nJede Nacht, jeden Tag auf der Jagd.\\nDenn das Rudel tollt, wenn der Rubel rollt.\\nJede Nacht, jeden Tag auf der Jagd.\\nDenn das Rudel tollt, wenn der Rubel rollt\\n\\nEine Pfote am Mikro, eine auf den Tasten.\\nEin Auge auf\\'s Geschäft, eines im Plattenkasten.\\nEin Ohr für\\'s Rudel und eins für den Gegner.\\nEin Tanzbein und ein Arschtreter.\\nEin Fuchs muss tun, was ein Fuchs tun muss.\\nLuxus und Ruhm und rulen bis zum Schluss.\\nDas ist mein Ziel, was ich noch nie so klar sah\\'.\\n„Sky is the limit.“ – Pah! Und was ist mit der NASA?\\n\\nSo sicher wie Wölfe bei Vollmond jaul\\'n.\\nElstern alles was glänzt klau\\'n.\\nSitzen wir als Füchse in unserem Bau drin.\\nFeilen mit roten Augen.\\nAn Tracks und Texten, bis sie was taugen.\\nDrin\\' alles ruhig, doch draußen wollen uns tausende unsere Ideen rauben.\\nEigentlich ist es Wahnsinn, Lieder wie diese \\'rauszubring\\'n.\\nWeil damit garantiert ist, dass die der Anderen bald auch so kling\\'n.\\nHamburg-City rult, wer behauptet was anderes?.\\nJetzt offiziell: Ich battle jeden MC, egal wie bekannt er ist.\\nMein Treibstoff ist Cannabis sativa.\\nDenn ich rapp\\' high lieber.\\nTag für Tag wieder.\\nLetztes Jahr schon Chart-Leader.\\nMit Denyo in der Style-Liga.\\nJetzt mal wieder ein fettes Feature.\\nMad mixt wie\\'n Barkeeper.\\nEißfeldt macht den Beat klar.\\nUnd schon schallt es durch eure Speaker.\\nWir gehen weiter und tiefer.\\nHamburg-City ist am Start.\\nAlso wie habt ihr\\'s lieber:.\\nAusgefuchst oder ausgelutscht? Für letzteres, geht zur Konkurrenz.\\nWir bleiben in Eimsbush.\\nund feiern fette Mongo-Jams!.\\n(Yeah! Yeah!)\\n\\nJede Nacht, jeden Tag auf der Jagd.\\nDenn das Jagen tollt, wenn der Rubel rollt!.\\nJede Nacht, jeden Tag auf der Jagd.\\nDenn das Rudel tollt, wenn der Rubel rollt.\\nJede Nacht, jeden Tag auf der Jagd.\\nDenn das Rudel rollt, wenn der Rubel tollt!.\\nTelefonklingeln.\\n- Eißfeldt?!.\\n\"Ja, hallo! Ich wollt mal sagen:.\\nFüchse sind gar keine Rudeltiere.\\n.\".\\n- Achso... Ja, ähm... Ja, egal, \\'s rhymed, ist fett, der Rhyme ist fett.\\n\"Gut, tschüß!\"',\n",
       " 'processed_lyrics': ['Wickeda-MC Flows pur Natur Sensi ',\n",
       "  'Freestyles näher Geschehen Hip-Hop-Fanzine ',\n",
       "  'Fuchs Materie   Möglichkeiten unbegrenzt gibt ',\n",
       "  \"folgen viele falschen Vorbildern lernen's \",\n",
       "  'Publikum rocken ner anderen Frequenz liegt ',\n",
       "  'betrifft Bühnenpräsenz liebt ',\n",
       "  'Rap-Exzellenz sieht Vorstellungskraft Vieler entzieht ',\n",
       "  'Sam Semilia ',\n",
       "  'Beginner kennt Woh ',\n",
       "  'Au Magen knurrt Sau ',\n",
       "  'hau Bau ',\n",
       "  \"Verschließ Tür ziehe durch's Revier \",\n",
       "  'Markier mal ',\n",
       "  'Höre Gelaber ',\n",
       "  'schleiche ',\n",
       "  'Promenade ',\n",
       "  'Zeuge Maskerade ',\n",
       "  'Buchstaben grelle Farben ',\n",
       "  'sagen Kabelfernsehen ',\n",
       "  'Gestiken Gerngesehenen Fuchs weiß ',\n",
       "  'ähnliche Garderobe Schutz heißt ',\n",
       "  'schnupper befindet ',\n",
       "  'Hut Udo ',\n",
       "  'Nacht Tag Jagd ',\n",
       "  'Rudel tollt Rubel rollt ',\n",
       "  'Nacht Tag Jagd ',\n",
       "  'Rudel tollt Rubel rollt ',\n",
       "  'Nacht Tag Jagd ',\n",
       "  'Rudel tollt Rubel rollt ',\n",
       "  'Nacht Tag Jagd ',\n",
       "  'Rudel tollt Rubel rollt ',\n",
       "  'Pfoten Gabi ',\n",
       "  'Mikros Boten Rap Schoten ',\n",
       "  'Verboten Quoten-MCs Boden toben ',\n",
       "  'Durchkreuzen Wälder älter ',\n",
       "  \"Alter wird's kälter \",\n",
       "  \"Egal für'n warmen Platz Major \",\n",
       "  'Press Vitamine Rap Orangen Granini ',\n",
       "  'Verteil Beginner-Sticker Panini ernten Platini ',\n",
       "  'I Style-tauschen ',\n",
       "  'Mega-Byte gestalt Hits reinlauschen ',\n",
       "  'Beats Reim rauschen Macht nix ',\n",
       "  \"dreckig kehr'n unter'n Teppich \",\n",
       "  'Grund ständig Loops aufgepeppt krieg ',\n",
       "  'vergeigen bloß ',\n",
       "  'egal Stricke reißen Galgen ',\n",
       "  'stylen ',\n",
       "  \"siehst List gefuchste Clips guckst'e Gigs \",\n",
       "  'Beginnern TV geklaut nix ',\n",
       "  'kriegt Futterneid leid soviel Geilheit ',\n",
       "  'Zahme ',\n",
       "  'Vögel ',\n",
       "  'singen Münchener Freiheit ',\n",
       "  'Sinneswandel Floskel ungeschminkt bleib ',\n",
       "  'werd bestimmt Amsel Drossel Fink bleib Star ',\n",
       "  'Nacht Tag Jagd ',\n",
       "  'Rudel tollt Rubel rollt ',\n",
       "  'Nacht Tag Jagd ',\n",
       "  'Rudel tollt Rubel rollt ',\n",
       "  'Nacht Tag Jagd ',\n",
       "  'Rudel tollt Rubel rollt ',\n",
       "  'Pfote Mikro Tasten ',\n",
       "  \"Auge auf's Geschäft Plattenkasten \",\n",
       "  \"Ohr für's Rudel eins Gegner \",\n",
       "  'Tanzbein Arschtreter ',\n",
       "  'Fuchs Fuchs ',\n",
       "  'Luxus Ruhm rulen Schluss ',\n",
       "  'Ziel klar sah ',\n",
       "  'Sky is the limit Pah NASA ',\n",
       "  \"sicher Wölfe Vollmond jaul'n \",\n",
       "  \"Elstern glänzt klau'n \",\n",
       "  'Sitzen Füchse Bau ',\n",
       "  'Feilen roten Augen ',\n",
       "  'Tracks Texten taugen ',\n",
       "  'Drin ruhig draußen tausende Ideen rauben ',\n",
       "  \"Eigentlich Wahnsinn Lieder rauszubring'n \",\n",
       "  \"garantiert Anderen kling'n \",\n",
       "  'Hamburg-City rult behauptet anderes ',\n",
       "  'offiziell battle MC egal ',\n",
       "  'Treibstoff Cannabis sativa ',\n",
       "  'rapp high ',\n",
       "  'Tag Tag ',\n",
       "  'Letztes Jahr Chart-Leader ',\n",
       "  'Denyo Style-Liga ',\n",
       "  'mal fettes Feature ',\n",
       "  \"Mad mixt wie'n Barkeeper \",\n",
       "  'Eißfeldt Beat klar ',\n",
       "  'schallt eure Speaker ',\n",
       "  'tiefer ',\n",
       "  'Hamburg-City Start ',\n",
       "  '',\n",
       "  'Ausgefuchst ausgelutscht letzteres Konkurrenz ',\n",
       "  'bleiben Eimsbush ',\n",
       "  'feiern fette Mongo-Jams ',\n",
       "  'Yeah Yeah ',\n",
       "  'Nacht Tag Jagd ',\n",
       "  'Jagen tollt Rubel rollt ',\n",
       "  'Nacht Tag Jagd ',\n",
       "  'Rudel tollt Rubel rollt ',\n",
       "  'Nacht Tag Jagd ',\n",
       "  'Rudel rollt Rubel tollt ',\n",
       "  'Telefonklingeln ',\n",
       "  'Eißfeldt ',\n",
       "  'hallo mal sagen ',\n",
       "  'Füchse Rudeltiere ',\n",
       "  '',\n",
       "  \"Achso ähm egal 's rhymed fett Rhyme fett \",\n",
       "  'tschüß ']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset['Beginner']['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "871e8c6e-5297-4a0f-8dcc-aecbdcef2770",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Word2Vec ###\n",
    "  ## preprocessing ##\n",
    "\n",
    "## Each sentence be placed in its own index and inside we will have the words of the sentence in a list \n",
    "processed_lyrics = []\n",
    "sentences_list = []\n",
    "for key in dataset.keys():\n",
    "    for idx in dataset[key]:\n",
    "        for sentence in dataset[key][idx]['processed_lyrics']:\n",
    "            processed_lyrics.append(sentence)\n",
    "            words_list = []\n",
    "            for word in sentence.split(\" \"):\n",
    "                if word == '':\n",
    "                    continue\n",
    "                words_list.append(word)\n",
    "            sentences_list.append(words_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "8265731f-412d-46a6-93aa-2cee90281d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['folgen', 'viele', 'falschen', 'Vorbildern', \"lernen's\"]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_lyrics[0]\n",
    "sentences_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6616c1eb-6e90-4891-94a6-da437ba807d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Word2Vec ###\n",
    "  ## preprocessing ##\n",
    "\n",
    "## Each sentence be placed in its own index and inside we will have the words of the sentence in a list \n",
    "processed_lyrics_lowcase = []\n",
    "sentences_list_lowcase = []\n",
    "for key in dataset.keys():\n",
    "    for idx in dataset[key]:\n",
    "        for sentence in dataset[key][idx]['processed_lyrics']:\n",
    "            words_list = []\n",
    "            words_string = \"\"\n",
    "            for word in sentence.split(\" \"):\n",
    "                if word == '':\n",
    "                    continue\n",
    "                if word[0].isupper():\n",
    "                    words_list.append(word.lower())\n",
    "                    words_string += word.lower() + \" \"\n",
    "            sentences_list_lowcase.append(words_list)\n",
    "            processed_lyrics_lowcase.append(words_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "920f40d7-719c-4f09-9296-77f80af894a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some manipulation of data to have larger 'sentences'\n",
    "i = 0\n",
    "temp_string = \"\"\n",
    "longer_strings = []\n",
    "longer_sentences = []\n",
    "temp_sent = []\n",
    "for sentence in sentences_list:\n",
    "    for word in sentence:\n",
    "        if i < 40:\n",
    "            temp_sent.append(word.lower())\n",
    "            temp_string += word.lower() + \" \"\n",
    "            i += 1\n",
    "        else:\n",
    "            i = 1\n",
    "            longer_sentences.append(temp_sent)\n",
    "            longer_strings.append(temp_string)\n",
    "            temp_sent = []\n",
    "            temp_string = \"\"\n",
    "            temp_string += word + \" \"\n",
    "            temp_sent.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "29120a95-94a3-4b3b-babc-353250c5ba22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knurrt',\n",
       " 'sau',\n",
       " 'hau',\n",
       " 'bau',\n",
       " 'verschließ',\n",
       " 'tür',\n",
       " 'ziehe',\n",
       " \"durch's\",\n",
       " 'revier',\n",
       " 'markier',\n",
       " 'mal',\n",
       " 'höre',\n",
       " 'gelaber',\n",
       " 'schleiche',\n",
       " 'promenade',\n",
       " 'zeuge',\n",
       " 'maskerade',\n",
       " 'buchstaben',\n",
       " 'grelle',\n",
       " 'farben']"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longer_strings[2]\n",
    "longer_sentences[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "c533d484-1179-47f0-a5d6-014e57fb033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training ##\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "bigrams = Phrases(longer_sentences, min_count=5, threshold=2)\n",
    "new_lines = [bigrams[line.split(\" \")] for line in longer_strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "fef840a2-6afd-462b-b84d-88cb90ac55ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating vocab of top words ##\n",
    "vocab = [word for sentence in longer_sentences for word in sentence]\n",
    "counter = Counter(vocab)\n",
    "vocab = [word[0] for word in counter.most_common(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2ca6b13a-1ee2-4175-b691-85a893305098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weiß'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "6e199f6e-ab3c-432c-99ad-2bddc9a1ffab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w2v = Word2Vec(sentences=new_lines, min_count=50, vector_size=200, window=10, workers=20)  ### your code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "198c0250-0c75-4a0c-bd90-6c0071d0df9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w2v.build_vocab(new_lines, min_count = 50) ### your code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "eb84a555-3f44-49b4-9576-48f697533c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54248914, 103446300)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.train(new_lines, epochs = 100, total_examples=w2v.corpus_count) ### your code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "1922064f-d5ec-4308-9097-7181c30a95f6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vater', 0.6659219264984131),\n",
       " ('lag', 0.2421538084745407),\n",
       " ('kind', 0.23708118498325348),\n",
       " ('gab', 0.23078513145446777),\n",
       " ('lehrer', 0.22680450975894928),\n",
       " ('bekam', 0.2243422120809555),\n",
       " ('mutter', 0.22265377640724182),\n",
       " ('eltern', 0.21760931611061096),\n",
       " ('denkt', 0.21479246020317078),\n",
       " ('job', 0.214352548122406),\n",
       " ('höre', 0.21342961490154266),\n",
       " ('schule', 0.20592470467090607),\n",
       " ('warst', 0.20409569144248962),\n",
       " ('sagte', 0.20310145616531372),\n",
       " ('jahr', 0.199281245470047),\n",
       " ('bringt', 0.1965971291065216),\n",
       " ('mom', 0.1916189044713974),\n",
       " ('kinder', 0.1887824982404709),\n",
       " ('kontakt', 0.18746133148670197),\n",
       " ('bezahlt', 0.1863062083721161)]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.similar_by_vector((w2v.wv.get_vector(\"vater\") - w2v.wv.get_vector(\"tot\")), topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "c16be0e8-a7dc-4369-9dd3-8865c9092a15",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fotze', 0.30678847432136536),\n",
       " ('kotzen', 0.3059578835964203),\n",
       " ('nutte', 0.2999865710735321),\n",
       " ('koks', 0.2737177610397339),\n",
       " ('lecker', 0.26625657081604004),\n",
       " ('zeige', 0.2574453353881836),\n",
       " ('pillen', 0.21938812732696533),\n",
       " ('clubs', 0.2177010029554367),\n",
       " ('Bitch', 0.21735909581184387),\n",
       " ('maybach', 0.2152678370475769),\n",
       " ('bmw', 0.20855097472667694),\n",
       " ('fick', 0.20701313018798828),\n",
       " ('yayo', 0.20612511038780212),\n",
       " ('’ne', 0.20466090738773346),\n",
       " ('bekommt', 0.20399445295333862),\n",
       " ('wodka', 0.2034698724746704),\n",
       " ('chick', 0.20120780169963837),\n",
       " ('Arsch', 0.2009485960006714),\n",
       " ('lächerlich', 0.19792573153972626),\n",
       " ('ne', 0.19767078757286072)]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(\"schlampe\", topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "dfc26745-0702-450f-87f2-0d3384651934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53836894, 102636100)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v2 = Word2Vec(sentences=new_lines, min_count=50, vector_size=200, window=10, workers=20)  ### your code ###\n",
    "w2v2.build_vocab(new_lines, min_count = 50) ### your code ###\n",
    "w2v2.train(new_lines, epochs = 100, total_examples=w2v.corpus_count) ### your code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "54bcc0d0-720b-4713-9811-8a572034a73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beamer', 0.3358168601989746),\n",
       " ('kilos', 0.3334430754184723),\n",
       " ('haze', 0.26742303371429443),\n",
       " ('cannabis', 0.2623513638973236),\n",
       " ('filme', 0.258696973323822),\n",
       " ('batzen', 0.2508927881717682),\n",
       " ('para', 0.24952782690525055),\n",
       " ('squad', 0.24947337806224823),\n",
       " ('ticker', 0.2430565059185028),\n",
       " ('frankfurt', 0.2421850562095642),\n",
       " ('ticken', 0.23554347455501556),\n",
       " ('kriminell', 0.2344028502702713),\n",
       " ('dicka', 0.23384280502796173),\n",
       " ('rapper', 0.2307867407798767),\n",
       " ('diggi', 0.23056194186210632),\n",
       " ('hip-hop', 0.22577889263629913),\n",
       " ('straße', 0.22545133531093597),\n",
       " ('wooh', 0.22114306688308716),\n",
       " ('kiez', 0.22109700739383698),\n",
       " ('verpackt', 0.21803018450737)]"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v2.wv.most_similar(\"dealer\", topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "9a563ec9-1b5c-43bf-b4ea-8bd837540e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Frau', 0.7372536063194275),\n",
       " ('Straße', 0.6250594854354858),\n",
       " ('Vater', 0.2779926061630249),\n",
       " ('kriegst', 0.2638784646987915),\n",
       " ('Kahba', 0.2520490884780884),\n",
       " ('Kissen', 0.24277158081531525),\n",
       " ('Label', 0.23462143540382385),\n",
       " ('Faust', 0.22711928188800812),\n",
       " ('küsst', 0.2250686138868332),\n",
       " ('Mutter', 0.22503824532032013),\n",
       " ('Frauen', 0.21073800325393677),\n",
       " ('Rechnung', 0.2058262676000595),\n",
       " ('Woche', 0.2040182203054428),\n",
       " ('Stich', 0.20082958042621613),\n",
       " ('Maul', 0.19981902837753296),\n",
       " ('fick', 0.19815170764923096),\n",
       " ('Ernst', 0.19718725979328156),\n",
       " ('Traum', 0.1954738199710846),\n",
       " ('Ausländer', 0.18353557586669922),\n",
       " ('geklaut', 0.18275777995586395)]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v2.wv.similar_by_vector(w2v2.wv.get_vector(\"Frau\") + w2v2.wv.get_vector(\"Straße\"), topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "bdd6a8f9-d078-4d9f-b9a2-fd869ae1a5e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'geld' not present in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [422], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m w2v2\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mmost_similar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeld\u001b[39m\u001b[38;5;124m\"\u001b[39m, topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\models\\keyedvectors.py:842\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[1;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    839\u001b[0m         weight[idx] \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    841\u001b[0m \u001b[38;5;66;03m# compute the weighted average of all keys\u001b[39;00m\n\u001b[1;32m--> 842\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mean_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_normalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_normalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    843\u001b[0m all_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_index(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, _KEY_TYPES) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_index_for(key)\n\u001b[0;32m    845\u001b[0m ]\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(topn, \u001b[38;5;28mint\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\models\\keyedvectors.py:519\u001b[0m, in \u001b[0;36mKeyedVectors.get_mean_vector\u001b[1;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[0;32m    517\u001b[0m         total_weight \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(weights[idx])\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_missing:\n\u001b[1;32m--> 519\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present in vocabulary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(total_weight \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    522\u001b[0m     mean \u001b[38;5;241m=\u001b[39m mean \u001b[38;5;241m/\u001b[39m total_weight\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'geld' not present in vocabulary\""
     ]
    }
   ],
   "source": [
    "w2v2.wv.most_similar(\"geld\", topn=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
