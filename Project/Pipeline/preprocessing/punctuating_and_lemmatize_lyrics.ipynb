{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05118efe-3d5a-466a-829f-4227f77791aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import matplotlib\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import json\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b93ca8-db76-4560-ad36-73e6e1355799",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load dataset\n",
    "with open('only_german_lyrics.json', 'r') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8508dab-fd03-48e2-bdec-603a5b3e4a92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#text & lemmatize \n",
    "nlp = spacy.load(\"de_core_news_sm\", exclude=\"ner\")\n",
    "with open(\"new_stopwords_de.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    stopwords_de = [line.rstrip() for line in f]\n",
    "f = IntProgress(min=0, max=5992) # instantiate the bar\n",
    "display(f) # display the bar\n",
    "word_list = []\n",
    "i = 0\n",
    "for key in dataset.keys():\n",
    "    for idx in dataset[key]:\n",
    "        text_filtered = []\n",
    "        lemma_filtered = []\n",
    "        for line in dataset[key][idx]['punctuated_lyrics'].split(\".\"):\n",
    "            line_list = \"\"\n",
    "            lemma_list = \"\"\n",
    "            for word in nlp(str(line)):\n",
    "                if not word.lemma_ in stopwords_de and word.has_vector:\n",
    "                    if not word.is_punct:\n",
    "                        line_list += word.text + \" \"\n",
    "                        lemma_list += word.lemma_ + \" \"\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            text_filtered.append(line_list)\n",
    "            lemma_filtered.append(lemma_list)\n",
    "        dataset[key][idx].update({'processed_lyrics_lemmatized' : text_filtered})\n",
    "        dataset[key][idx].update({'processed_lyrics_text' : lemma_filtered})\n",
    "        f.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f5f59-f717-4aee-9d0e-20c9babb9548",
   "metadata": {},
   "outputs": [],
   "source": [
    "## punctuation\n",
    "from deepmultilingualpunctuation import PunctuationModel\n",
    "model = PunctuationModel()\n",
    "f = IntProgress(min=0, max=5992) # instantiate the bar\n",
    "display(f) # display the bar\n",
    "for key in dataset.keys():\n",
    "    for idx in dataset[key]:\n",
    "        print(f.value)\n",
    "        result = \"\"\n",
    "        text = dataset[key][idx]['lyrics']\n",
    "        try:\n",
    "            result = model.restore_punctuation(text)\n",
    "        except:\n",
    "            print(\"Failed at song key:\", key, \"idx: \", idx)\n",
    "        dataset[key][idx]['punctuated_lyrics'] = result\n",
    "        f.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe746a53-f5c1-4c80-9f93-0440e9bbaf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new dictionary as .json\n",
    "with open('punctuated_german_lyrics' + '.json', 'w', encoding='utf8') as f:\n",
    "    json.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846029af-e199-4fa9-83e2-0e0d80a43bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text & lemmatize \n",
    "nlp = spacy.load(\"de_core_news_sm\", exclude=\"ner\")\n",
    "with open(\"new_stopwords_de.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    stopwords_de = [line.rstrip() for line in f]\n",
    "f = IntProgress(min=0, max=5992) # instantiate the bar\n",
    "display(f) # display the bar\n",
    "word_list = []\n",
    "i = 0\n",
    "for key in dataset.keys():\n",
    "    for idx in dataset[key]:\n",
    "        text_filtered = []\n",
    "        lemma_filtered = []\n",
    "        for line in dataset[key][idx]['punctuated_lyrics'].split(\".\"):\n",
    "            line_list = \"\"\n",
    "            lemma_list = \"\"\n",
    "            for word in nlp(str(line)):\n",
    "                if not word.lemma_ in stopwords_de and word.has_vector:\n",
    "                    if not word.is_punct:\n",
    "                        line_list += word.text + \" \"\n",
    "                        lemma_list += word.lemma_ + \" \"\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            text_filtered.append(line_list)\n",
    "            lemma_filtered.append(lemma_list)\n",
    "        dataset[key][idx].update({'processed_lyrics_lemmatized' : text_filtered})\n",
    "        dataset[key][idx].update({'processed_lyrics_text' : lemma_filtered})\n",
    "        f.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67768a75-3c10-4e41-9955-b57bfaa3da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new dictionary as .json\n",
    "with open('punctuated_lemmatized_german_lyrics' + '.json', 'w', encoding='utf8') as f:\n",
    "    json.dump(dataset, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
