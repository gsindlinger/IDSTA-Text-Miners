{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6c3d673-2b4b-4b78-939d-4b1fcfb9f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from random import randrange\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40df4a00-61de-4d1a-8a0f-a114b014d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/lyrics.json', 'r', encoding='utf8') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19ad5515-d588-4c68-932f-c4f338ebab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining two dictionaries for bidirectional mapping between int & class\n",
    "class_to_int = {'neutral' : 0, 'liebevoll' : 1, 'gewalttätig' : 2, 'rassistisch' : 3,\n",
    "                   'homophob' : 4, 'frauenfeindlich' : 5, 'freundlich' : 6, 'positiv' : 7, 'traurig' : 8}\n",
    "int_to_class = {v: k for k, v in class_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d01240a-e558-4eb1-8753-5387b5dabeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highest_class(song):\n",
    "    max_class = 0\n",
    "    highest_score = 0\n",
    "    for key, value in song['total_class_score'].items():\n",
    "        if highest_score < value:\n",
    "            max_class = class_to_int[key]\n",
    "            highest_score = value\n",
    "    return max_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ad3fa34-6f6d-4d8f-8a8b-2e01a6b7a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a list where each element represents the highest scoring class for each song from 0 to n\n",
    "n = 100\n",
    "predictions = []\n",
    "for song in dataset[100:200]:\n",
    "    max_class = 0\n",
    "    highest_score = 0\n",
    "    for key, value in song['total_class_score'].items():\n",
    "        if highest_score < value:\n",
    "            max_class = class_to_int[key]\n",
    "            highest_score = value\n",
    "    predictions.append(max_class)\n",
    "    \n",
    "truth = [randrange(8) for i in range(0,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3d3e213-07bc-42c3-a7e4-092e3d1709f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = []\n",
    "kek.append(dataset[0])\n",
    "if not dataset[0] in kek:\n",
    "    print(\"shit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e938b91-d6de-4702-bab6-0fbde1fb0bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## randomly sample n songs for each class to a total of 9*n (9 classes)\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "total = 0\n",
    "n = 10\n",
    "attempts = 0\n",
    "samples = []\n",
    "random.seed(237)\n",
    "\n",
    "for i in range(9):\n",
    "    elist = []\n",
    "    samples.append(elist)\n",
    "while total < 9*n and attempts < 1000:\n",
    "    idx = randrange(len(dataset))\n",
    "    class_number = get_highest_class(dataset[idx])\n",
    "    if (not dataset[idx] in samples[class_number]) and (len(samples[class_number]) < n):\n",
    "        dataset[idx]['top_class'] = class_number\n",
    "        samples[class_number].append(dataset[idx])\n",
    "        total += 1\n",
    "    attempts += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7cf0e85-a74b-4e7d-8428-e98dfa56d4c6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4948490\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for list in samples:\n",
    "    count += len(list)\n",
    "\n",
    "count\n",
    "\n",
    "count = 0\n",
    "for list in samples:\n",
    "    for song in list:\n",
    "        if count == 35:\n",
    "            print(song['genius_track_id'])\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47eebabb-ce2e-4041-9604-8d7076eb5b94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.00      0.00      0.00        17\n",
      "           2       0.17      0.31      0.22        13\n",
      "           3       0.00      0.00      0.00        13\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.00      0.00      0.00        14\n",
      "           6       0.12      0.25      0.17         8\n",
      "           7       0.10      0.33      0.15        12\n",
      "           8       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.10       100\n",
      "   macro avg       0.04      0.10      0.06       100\n",
      "weighted avg       0.04      0.10      0.06       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "## we're interested in the macro-avg\n",
    "print(classification_report(truth, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7e01cce-15a8-4514-9805-8978c9a10875",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculating the number of songs labeled per each class\n",
    "\n",
    "class_scores = {0 : 0, 1 : 0, 2 : 0, 3 : 0,\n",
    "                   4 : 0, 5 : 0, 6 : 0, 7 : 0, 8 : 0}\n",
    "\n",
    "for song in dataset:\n",
    "    max_class = 0\n",
    "    highest_score = 0\n",
    "    for key, value in song['total_class_score'].items():\n",
    "        if highest_score < value:\n",
    "            max_class = class_to_int[key]\n",
    "            highest_score = value\n",
    "    class_scores[max_class] += 1\n",
    "\n",
    "## convert\n",
    "class_scores = {int_to_class[k]: v for k, v in class_scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dee09ca5-aeda-4d5c-a979-07514ab3c310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 167,\n",
       " 'liebevoll': 227,\n",
       " 'gewalttätig': 935,\n",
       " 'rassistisch': 0,\n",
       " 'homophob': 0,\n",
       " 'frauenfeindlich': 76,\n",
       " 'freundlich': 1732,\n",
       " 'positiv': 2149,\n",
       " 'traurig': 706}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182ca7a-f9e8-4533-b1b2-c5d13505af0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
