\section{Conclusion}\label{sec:conclusion}

During our work on the project, we encountered different difficulties that posed limitations to our ability to process the songs correctly.
One of the main issues we dealt with was the way the texts are written. Due to the nature of the language used very often in German rap, such as slang, juvenile words, foreign words, and the texts being written and spelled phonetically and not the way they should be spelled, preprocessing those texts by means of NLP (such as lemmatization, tokenization, which all relay heavily on and follows a set of grammatical rules) was very difficult. For example, many words are spelled phonetically, e.g. in the way they're being spoken. An example of such a case is - ich hab' instead of ich habe. Another example is eine spelled as 'ne. In other cases, nouns weren't written with a capital letter, which made it hard to distinguish whether it is a verb or a noun.  Due to those deviations from how the words should be written, lemmatization or the removal of stopwords will fail to work. In such a case, the word 'ne wouldn't be removed because it's not being detected as a stopword. We've tried to get around this issue by using regex, but it was impossible to address all the different cases. During our attempts we've noticed that words, that shouldn't be influenced by the different regex rules that we tried to use, were changed, thus rendering this option completely useless.
This made it impossible, for example, to correctly learn the vocabulary of those songs using methods like Word2Vec. The same word, depending on how it is written, was treated as 2 different words (for example, in the case of hab' and habe, those were considered to be two different words).
Another issue that could've potentially limited our results, even more, was the lack of punctuation. For correct processing of the texts, entire songs should be correctly split up into different sentences. The lack of punctuation, in this case, prevented us from being able to understand what word belongs to which part of the text. We were able to get solve this issue with the auto-punctuator model mentioned in the pipeline part. Without this solution, it would've been very difficult to process the songs even with pre-trained models.